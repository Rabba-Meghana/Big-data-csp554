# Electricity Consumption Forecasting â€“ Deep Learning Module  
CSP 554 â€“ Big Data Technologies  
**Author:** Chaitanya Datta MAddukuri
**Task:** Individual Deep Learning Component  

---

## ğŸ“Œ Overview  
This module focuses on developing **deep learning forecasting models** (LSTM and GRU) using hourly electricity consumption data.  
It is part of an end-to-end big data forecasting pipeline using AWS S3, Spark, and SageMaker.

Your tasks completed in this module:
- Load cleaned, processed dataset from S3  
- Create supervised time-series sequences (past 24 hours â†’ next hour)  
- Build small deep learning models (LSTM, GRU)  
- Train both and compare validation metrics  
- Select the best performing model  
- Export model in TensorFlow SavedModel format  
- Upload model to an S3 bucket for deployment  

---

## ğŸ“ Project Structure

deep_learning/
â”‚â”€â”€ config.py # S3 paths, model directory config
â”‚â”€â”€ data_loader.py # Download + load dataset from S3
â”‚â”€â”€ sequence_prep.py # Create 24-hour input sequences
â”‚â”€â”€ models.py # LSTM and GRU model definitions
â”‚â”€â”€ train.py # Full training pipeline
â”‚â”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # This file


---

## ğŸš€ How It Works

### 1ï¸âƒ£ **Load Dataset from S3**
The script downloads the final processed dataset (Parquet format) into `data/`.

### 2ï¸âƒ£ **Prepare Sequences**
- Normalize consumption values  
- Use 24-hour history as input  
- Predict next hour consumption  

### 3ï¸âƒ£ **Build Models**
Two lightweight models:  
- **LSTM (32 units + dropout)**  
- **GRU (32 units + dropout)**  

### 4ï¸âƒ£ **Train + Compare**
Both models are trained with:
- Validation split  
- MAE, MSE metrics  
- Dropout to reduce overfitting  

The best model is selected based on **validation MAE**.

### 5ï¸âƒ£ **Save and Upload**
The best model is saved in: saved_model/

Then uploaded automatically to your S3 model bucket.

---

## ğŸ› ï¸ Installation

### Install dependencies:
```bash
pip install -r requirements.txt

### Configure AWS Credentials:
aws configure

### Run Training:
python train.py

This will:

-Download data from S3
-Train LSTM & GRU
-Pick the best model
-Save to saved_model/
-Upload to S3 for SageMaker deployment

